use core::sync::atomic::{AtomicUsize, Ordering};

const HEAP_SIZE: usize = 127 * 1024 * 1024; // 127MB
const HEAP_START: usize = 0x3000;

static HEAP_PTR: AtomicUsize = AtomicUsize::new(HEAP_START);

pub fn alloc(size: usize) -> *mut u8 {
    // Align to 8 bytes
    let aligned_size = (size + 7) & !7;

    // Atomically fetch and add
    let ptr = HEAP_PTR.fetch_add(aligned_size, Ordering::SeqCst);

    // Check bounds
    if ptr + aligned_size > HEAP_START + HEAP_SIZE {
        return core::ptr::null_mut(); // OOM
    }

    ptr as *mut u8
}

pub fn dealloc(_ptr: *mut u8, _size: usize) {
    // Bump allocator doesn't support individual deallocation
}

// Reset allocator (called at start of each analysis)
#[allow(dead_code)]
pub fn reset_heap() {
    HEAP_PTR.store(HEAP_START, Ordering::SeqCst);
}
