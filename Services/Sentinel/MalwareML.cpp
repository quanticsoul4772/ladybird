/*
 * Copyright (c) 2025, Ladybird contributors
 * SPDX-License-Identifier: BSD-2-Clause
 */

#include "MalwareML.h"
#include <AK/Checked.h>
#include <AK/Math.h>
#include <AK/Time.h>

// TensorFlow Lite headers when available
#ifdef ENABLE_TFLITE
#include <tensorflow/lite/interpreter.h>
#include <tensorflow/lite/kernels/register.h>
#include <tensorflow/lite/model.h>
#endif

namespace Sentinel {

#ifdef USE_ML_STUB
// Implementation of MalwareMLStub methods
MalwareMLStub::MalwareMLStub() {
    // Initialize with pseudo-random weights that simulate a trained model
    // These weights are crafted to detect high entropy and suspicious patterns
    initialize_weights();
}

MalwareMLStub::~MalwareMLStub() {
    // Empty destructor - explicitly defined to ensure proper cleanup
}

void MalwareMLStub::initialize_weights() {
        // IMPORTANT: Zero-initialize all arrays first to prevent garbage values
        for (size_t i = 0; i < INPUT_SIZE; i++) {
            for (size_t j = 0; j < HIDDEN_SIZE; j++) {
                weights_input_hidden[i][j] = 0.0f;
            }
        }
        for (size_t i = 0; i < HIDDEN_SIZE; i++) {
            for (size_t j = 0; j < OUTPUT_SIZE; j++) {
                weights_hidden_output[i][j] = 0.0f;
            }
        }
        for (size_t i = 0; i < HIDDEN_SIZE; i++) {
            bias_hidden[i] = 0.0f;
        }
        for (size_t i = 0; i < OUTPUT_SIZE; i++) {
            bias_output[i] = 0.0f;
        }

        // Input to hidden layer weights - manually set key connections only
        // Entropy (feature 1) -> hidden neurons with positive weights for malware detection
        weights_input_hidden[1][0] = 0.6f;   // Entropy -> neuron 0 (strong indicator)
        weights_input_hidden[1][1] = 0.5f;   // Entropy -> neuron 1
        weights_input_hidden[1][2] = 0.4f;   // Entropy -> neuron 2
        weights_input_hidden[1][3] = 0.3f;   // Entropy -> neuron 3

        // PE anomalies (feature 2) -> hidden neurons
        weights_input_hidden[2][4] = 0.4f;   // PE anomalies -> neuron 4
        weights_input_hidden[2][5] = 0.3f;   // PE anomalies -> neuron 5

        // Suspicious strings (feature 3) -> hidden neurons
        weights_input_hidden[3][6] = 0.4f;   // Suspicious strings -> neuron 6
        weights_input_hidden[3][7] = 0.3f;   // Suspicious strings -> neuron 7
        weights_input_hidden[3][8] = 0.2f;   // Suspicious strings -> neuron 8

        // File size (feature 0) -> small positive weights
        weights_input_hidden[0][9] = 0.1f;
        weights_input_hidden[0][10] = 0.1f;

        // Code ratio and imports -> minimal weights
        weights_input_hidden[4][11] = 0.1f;   // Code ratio
        weights_input_hidden[5][12] = 0.1f;  // Imports

        // Hidden layer bias (small values)
        for (size_t i = 0; i < HIDDEN_SIZE; i++) {
            bias_hidden[i] = -0.1f + (i % 3) * 0.05f;
        }

        // Hidden to output weights (adjusted for better discrimination)
        for (size_t i = 0; i < HIDDEN_SIZE; i++) {
            weights_hidden_output[i][0] = -0.06f - (i % 4) * 0.01f;  // Benign: -0.06 to -0.09
            weights_hidden_output[i][1] = 0.06f + (i % 4) * 0.01f;   // Malware: 0.06 to 0.09
        }

        // Output bias (reduced to let features dominate)
        bias_output[0] = 0.05f;    // Benign - reduced bias
        bias_output[1] = -0.05f;   // Malware - reduced bias
}

// Forward pass through the network
Vector<float> MalwareMLStub::forward(Vector<float> const& input) {
        VERIFY(input.size() == INPUT_SIZE);

        // Hidden layer computation
        float hidden[HIDDEN_SIZE];
        for (size_t j = 0; j < HIDDEN_SIZE; j++) {
            hidden[j] = bias_hidden[j];
            for (size_t i = 0; i < INPUT_SIZE; i++) {
                hidden[j] += input[i] * weights_input_hidden[i][j];
            }
            hidden[j] = relu(hidden[j]);
        }

        // Output layer computation
        float output_raw[OUTPUT_SIZE];
        for (size_t j = 0; j < OUTPUT_SIZE; j++) {
            output_raw[j] = bias_output[j];
            for (size_t i = 0; i < HIDDEN_SIZE; i++) {
                output_raw[j] += hidden[i] * weights_hidden_output[i][j];
            }
        }

        // Apply softmax for probability distribution
        float max_val = AK::max(output_raw[0], output_raw[1]);
        float exp_sum = 0;
        for (size_t i = 0; i < OUTPUT_SIZE; i++) {
            output_raw[i] = AK::exp(output_raw[i] - max_val);
            exp_sum += output_raw[i];
        }

        Vector<float> output;
        output.ensure_capacity(OUTPUT_SIZE);
        for (size_t i = 0; i < OUTPUT_SIZE; i++) {
            output.append(output_raw[i] / exp_sum);
        }

        return output;
}
#endif

// Feature vector conversion
Vector<float> MalwareMLDetector::Features::to_vector() const
{
    Vector<float> vec;
    vec.ensure_capacity(6); // 6 features total

    // Normalize features to 0.0-1.0 range for neural network
    vec.append(static_cast<float>(file_size) / 100'000'000.0f); // Normalize by 100MB
    vec.append(entropy / 8.0f);                                  // Entropy is 0-8
    vec.append(static_cast<float>(pe_header_anomalies) / 100.0f); // Max ~100 anomalies
    vec.append(static_cast<float>(suspicious_strings) / 1000.0f); // Max ~1000 strings
    vec.append(code_section_ratio);                              // Already 0-1
    vec.append(static_cast<float>(import_table_size) / 500.0f);  // Max ~500 imports

    return vec;
}

// Constructor
MalwareMLDetector::MalwareMLDetector(ByteString const& model_path)
    : m_model_path(model_path)
{
    m_input_tensor.resize(6);   // 6-dimensional input
    m_output_tensor.resize(2);  // Binary classification output [benign, malware]

    // Explicitly zero-initialize statistics
    m_stats.total_predictions = 0;
    m_stats.malware_detected = 0;
    m_stats.benign_classified = 0;
    m_stats.average_inference_time_ms = 0.0f;
    m_stats.average_confidence = 0.0f;
}

// Destructor
MalwareMLDetector::~MalwareMLDetector()
{
    // Empty destructor - explicitly defined to ensure proper cleanup order
}

// Factory method
ErrorOr<NonnullOwnPtr<MalwareMLDetector>> MalwareMLDetector::create(ByteString const& model_path)
{
    auto detector = adopt_own(*new MalwareMLDetector(model_path));
    TRY(detector->load_model());
    TRY(detector->initialize_interpreter());
    return detector;
}

// Load TensorFlow Lite model
ErrorOr<void> MalwareMLDetector::load_model()
{
#ifdef ENABLE_TFLITE
    // Real TensorFlow Lite integration
    auto model = tflite::FlatBufferModel::BuildFromFile(m_model_path.characters());
    if (!model) {
        return Error::from_string_literal("Failed to load TFLite model");
    }
    m_model = model.release();
    m_model_loaded = true;
    m_model_version = "1.0.0-tflite"_string;
#elif defined(USE_ML_STUB)
    // Use ML stub for demonstration
    m_ml_stub = adopt_own(*new MalwareMLStub());
    m_model_loaded = true;
    m_model_version = "1.0.0-stub"_string;
#else
    // Fallback to heuristic mode
    m_model_loaded = true;
    m_model_version = "1.0.0-heuristic"_string;
#endif

    return {};
}

// Initialize TensorFlow Lite interpreter
ErrorOr<void> MalwareMLDetector::initialize_interpreter()
{
    if (!m_model_loaded)
        return Error::from_string_literal("Model not loaded");

#ifdef ENABLE_TFLITE
    // Real TensorFlow Lite interpreter
    tflite::ops::builtin::BuiltinOpResolver resolver;
    tflite::InterpreterBuilder builder(*static_cast<tflite::FlatBufferModel*>(m_model), resolver);

    auto interpreter = std::make_unique<tflite::Interpreter>();
    if (builder(&interpreter) != kTfLiteOk || !interpreter) {
        return Error::from_string_literal("Failed to build interpreter");
    }

    if (interpreter->AllocateTensors() != kTfLiteOk) {
        return Error::from_string_literal("Failed to allocate tensors");
    }

    m_interpreter = interpreter.release();
#elif defined(USE_ML_STUB)
    // ML stub is already initialized
#else
    // No interpreter needed for heuristic mode
#endif

    return {};
}

// Shannon entropy calculation (information theory)
float MalwareMLDetector::calculate_shannon_entropy(ByteBuffer const& data)
{
    if (data.is_empty())
        return 0.0f;

    // Count byte frequency
    u32 frequency[256] = { 0 };
    for (auto byte : data.bytes())
        frequency[byte]++;

    // Calculate entropy
    float entropy = 0.0f;
    float data_size = static_cast<float>(data.size());

    for (size_t i = 0; i < 256; i++) {
        if (frequency[i] == 0)
            continue;

        float probability = static_cast<float>(frequency[i]) / data_size;
        entropy -= probability * AK::log2(probability);
    }

    return entropy;
}

// Count suspicious strings (URLs, IPs, high-entropy strings)
u32 MalwareMLDetector::count_suspicious_strings(ByteBuffer const& data)
{
    u32 count = 0;
    auto view = StringView(data.bytes());

    // Look for URL patterns (http://, https://, ftp://)
    if (view.contains("http://"sv) || view.contains("https://"sv) || view.contains("ftp://"sv))
        count += 10;

    // Look for IP address patterns (simplified)
    // In real implementation, use regex: \d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3}
    if (view.length() >= 7) {
        for (size_t i = 0; i < view.length() - 7; i++) {
            if (view[i] >= '0' && view[i] <= '9') {
                // Simple heuristic: count sequences like "192.168."
                auto substr = view.substring_view(i, min(view.length() - i, 7ul));
                if (substr.contains('.')) {
                    count += 5;
                    i += 7; // Skip ahead
                }
            }
        }
    }

    // Look for executable patterns
    if (view.contains(".exe"sv) || view.contains(".dll"sv) || view.contains(".bat"sv))
        count += 3;

    // Look for suspicious API calls (Windows)
    if (view.contains("VirtualAlloc"sv) || view.contains("CreateRemoteThread"sv) ||
        view.contains("WriteProcessMemory"sv))
        count += 15; // High weight for suspicious APIs

    return min(count, 1000u); // Cap at 1000
}

// Check if file is a PE (Portable Executable) - Windows format
bool MalwareMLDetector::is_pe_file(ByteBuffer const& data)
{
    if (data.size() < 64)
        return false;

    // Check for DOS header "MZ"
    return data.bytes()[0] == 'M' && data.bytes()[1] == 'Z';
}

// Analyze PE structure for anomalies
u32 MalwareMLDetector::analyze_pe_structure(ByteBuffer const& data)
{
    if (!is_pe_file(data))
        return 0;

    u32 anomalies = 0;

    // Check DOS header
    if (data.size() < 64)
        return 100; // Truncated PE = highly suspicious

    // Read PE offset from DOS header (at offset 0x3C)
    u32 pe_offset = static_cast<u32>(data.bytes()[0x3C]) |
                    (static_cast<u32>(data.bytes()[0x3D]) << 8) |
                    (static_cast<u32>(data.bytes()[0x3E]) << 16) |
                    (static_cast<u32>(data.bytes()[0x3F]) << 24);

    // Check for valid PE offset
    if (pe_offset > data.size() - 4)
        return 50; // Invalid PE offset

    // Check for PE signature "PE\0\0"
    if (pe_offset + 4 <= data.size()) {
        if (!(data.bytes()[pe_offset] == 'P' && data.bytes()[pe_offset + 1] == 'E' &&
              data.bytes()[pe_offset + 2] == 0 && data.bytes()[pe_offset + 3] == 0))
            anomalies += 20; // Invalid PE signature
    }

    // In a full implementation, we'd check:
    // - Section count (unusual if >10)
    // - Entry point location (should be in .text section)
    // - Import table validity
    // - Export table validity
    // - Resource section size
    // - Code signing presence

    return min(anomalies, 100u);
}

// Calculate code to data ratio
float MalwareMLDetector::calculate_code_ratio(ByteBuffer const& data)
{
    if (!is_pe_file(data) || data.size() < 1024)
        return 0.5f; // Default for non-PE or small files

    // Simplified heuristic: count executable bytes vs. null/data bytes
    u32 code_bytes = 0;
    u32 data_bytes = 0;

    for (size_t i = 64; i < min(data.size(), 10240ul); i++) { // Sample first ~10KB after header
        u8 byte = data.bytes()[i];

        // Heuristic: 0x00, 0xFF are likely data/padding
        if (byte == 0x00 || byte == 0xFF)
            data_bytes++;
        // x86/x64 instruction opcodes are typically in certain ranges
        else if ((byte >= 0x40 && byte <= 0x5F) || // REX prefix, PUSH/POP
                 (byte >= 0x80 && byte <= 0x8F) || // Conditional jumps
                 (byte == 0xE8 || byte == 0xE9))   // CALL, JMP
            code_bytes++;
        else
            data_bytes++;
    }

    if (code_bytes + data_bytes == 0)
        return 0.5f;

    return static_cast<float>(code_bytes) / static_cast<float>(code_bytes + data_bytes);
}

// Extract import table size (Windows PE)
u32 MalwareMLDetector::extract_import_table_size(ByteBuffer const& data)
{
    if (!is_pe_file(data))
        return 0;

    // Simplified: count likely import names
    // Real implementation would parse PE import directory
    u32 import_count = 0;

    // Common Windows DLLs and API names
    Vector<StringView> common_dlls = {
        "kernel32.dll"sv, "user32.dll"sv, "advapi32.dll"sv,
        "ntdll.dll"sv, "ws2_32.dll"sv, "wininet.dll"sv
    };

    auto view = StringView(data.bytes());
    for (auto dll : common_dlls) {
        if (view.contains(dll))
            import_count += 10; // Estimate ~10 imports per DLL
    }

    return min(import_count, 500u);
}

// Extract features from file
ErrorOr<MalwareMLDetector::Features> MalwareMLDetector::extract_features(ByteBuffer const& file_data)
{
    Features features;

    features.file_size = file_data.size();
    features.entropy = calculate_shannon_entropy(file_data);
    features.suspicious_strings = count_suspicious_strings(file_data);

    if (is_pe_file(file_data)) {
        features.pe_header_anomalies = analyze_pe_structure(file_data);
        features.code_section_ratio = calculate_code_ratio(file_data);
        features.import_table_size = extract_import_table_size(file_data);
    }

    return features;
}

// Run prediction
ErrorOr<MalwareMLDetector::Prediction> MalwareMLDetector::predict(Features const& features)
{
    if (!m_model_loaded)
        return Error::from_string_literal("ML model not loaded");

    auto start_time = MonotonicTime::now();

    Prediction prediction;
    prediction.features_used = features;

    // Convert features to input tensor
    m_input_tensor = features.to_vector();

#ifdef ENABLE_TFLITE
    // Real TensorFlow Lite inference
    auto* interpreter = static_cast<tflite::Interpreter*>(m_interpreter);

    // Copy input data to interpreter
    float* input = interpreter->typed_input_tensor<float>(0);
    memcpy(input, m_input_tensor.data(), m_input_tensor.size() * sizeof(float));

    // Run inference
    if (interpreter->Invoke() != kTfLiteOk) {
        return Error::from_string_literal("Inference failed");
    }

    // Get output
    float* output = interpreter->typed_output_tensor<float>(0);
    m_output_tensor[0] = output[0];  // Benign probability
    m_output_tensor[1] = output[1];  // Malware probability

    prediction.malware_probability = m_output_tensor[1];
    prediction.confidence = AK::max(m_output_tensor[0], m_output_tensor[1]);

#elif defined(USE_ML_STUB)
    // ML stub inference - simulated neural network
    auto output = m_ml_stub->forward(m_input_tensor);
    VERIFY(output.size() == 2);

    m_output_tensor = output;
    prediction.malware_probability = output[1];  // Malware class probability
    prediction.confidence = AK::max(output[0], output[1]);

#else
    // Heuristic-based scoring fallback
    float score = 0.0f;

    // High entropy suggests encryption/packing (common in malware)
    if (features.entropy > 7.0f) score += 0.3f;
    else if (features.entropy > 6.0f) score += 0.15f;

    // PE anomalies
    if (features.pe_header_anomalies > 20) score += 0.25f;
    else if (features.pe_header_anomalies > 5) score += 0.1f;

    // Suspicious strings
    if (features.suspicious_strings > 50) score += 0.3f;
    else if (features.suspicious_strings > 20) score += 0.15f;

    // Unusual code ratio (too high or too low)
    if (features.code_section_ratio < 0.2f || features.code_section_ratio > 0.9f)
        score += 0.15f;

    prediction.malware_probability = min(score, 1.0f);
    prediction.confidence = 0.85f; // Heuristic confidence
#endif

    prediction.explanation = generate_explanation(features, prediction.malware_probability);

    // Update statistics
    auto elapsed = MonotonicTime::now() - start_time;
    m_stats.total_predictions++;
    if (prediction.malware_probability > 0.5f)
        m_stats.malware_detected++;
    else
        m_stats.benign_classified++;

    m_stats.average_inference_time_ms =
        (m_stats.average_inference_time_ms * (m_stats.total_predictions - 1) +
         static_cast<float>(elapsed.to_milliseconds())) / m_stats.total_predictions;

    m_stats.average_confidence =
        (m_stats.average_confidence * (m_stats.total_predictions - 1) +
         prediction.confidence) / m_stats.total_predictions;

    return prediction;
}

// Convenience method
ErrorOr<MalwareMLDetector::Prediction> MalwareMLDetector::analyze_file(ByteBuffer const& file_data)
{
    auto features = TRY(extract_features(file_data));
    return predict(features);
}

// Generate human-readable explanation
String MalwareMLDetector::generate_explanation(Features const& features, float probability)
{
    Vector<String> reasons;

    if (features.entropy > 7.0f)
        reasons.append(MUST(String::formatted("High entropy ({:.2f}) suggests encryption/packing", features.entropy)));

    if (features.pe_header_anomalies > 20)
        reasons.append(MUST(String::formatted("{} PE structure anomalies detected", features.pe_header_anomalies)));

    if (features.suspicious_strings > 50)
        reasons.append(MUST(String::formatted("{} suspicious strings found (URLs, APIs)", features.suspicious_strings)));

    if (features.code_section_ratio < 0.2f)
        reasons.append("Unusually low code ratio"_string);
    else if (features.code_section_ratio > 0.9f)
        reasons.append("Unusually high code ratio"_string);

    if (reasons.is_empty()) {
        if (probability > 0.5f)
            return "Multiple weak indicators suggest potential malware"_string;
        else
            return "File appears benign based on structural analysis"_string;
    }

    // Join reasons with semicolons
    StringBuilder builder;
    for (size_t i = 0; i < reasons.size(); i++) {
        builder.append(reasons[i]);
        if (i < reasons.size() - 1)
            builder.append("; "_string);
    }

    return MUST(builder.to_string());
}

// Get statistics
MalwareMLDetector::Statistics MalwareMLDetector::get_statistics() const
{
    Statistics result;
    result.total_predictions = m_stats.total_predictions;
    result.malware_detected = m_stats.malware_detected;
    result.benign_classified = m_stats.benign_classified;
    result.average_inference_time_ms = m_stats.average_inference_time_ms;
    result.average_confidence = m_stats.average_confidence;

    return result;
}

// Reset statistics
void MalwareMLDetector::reset_statistics()
{
    m_stats = Statistics {};
}

}
